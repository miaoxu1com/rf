python  数据存储  cvs格式存储 有自己特有的格式 就是用逗号分隔  然后是文本类型的可以使用编辑器 直接打开
execel  是二进制文件不能用文本编辑器直接打开  
config  文件只能保存二维的数据 不能在节点key下载再创建key value如果  [config]  language=name=en
那么name就会被识别为字符串  如果要使用就要在python中再次解析为 对象才行
dump  load  dumps   loads 就是 带s 是 str->dict  不带s的 就是文本到序列化为json的写文件数据
而且如果是关系型数据  就要用到关系型数据库 
如果非关系型数据可以用  文本文件类型存储  但是大量文件时还是要用数据库  如果数据就是一块一块的  没有关系 用redis存json 在服务端则可以减少数据的转换  mongon

如果输出的数据还需要后续 筛选查看 可能需要二次分析  用excel更合适  select过滤 query查询  


命令行的输出一般都很有规律 比如 ping输出格式
来自 192.168.1.1 字节=32 ttl=55 可以把输出copy出来然后 放入excel进行 分列有的可能需要多次分列达到自己想要的  然后再排序这样就可以得到有规律的数据 筛选出可ping 的ip

excel可以直接选中一列数据然后插入  推荐的表格自动生成 透视表很有用 帮助分析
excel动态化图表可以用vb插件下拉框动态化改变 图表数据  主要是通过控件绑定数据实现的  为什么必须要控件

序列化就是格式化成字符串

还有就是字符串格式化  如果是 json 字符串格式化  里边有很多要替换的  为了保持json的结构 就不要用 + 进行拼接会很乱  这个时候可以用'''
{
  "name":"zhagnsna"
  "age":['30']
}
'''

excel中文本后缀不会加0




多线程   高并发  就是集群开发 比如redis集群  数据库集群  niginx集群等等  这些就是高并发

还有就是一些任务适合什么数据库也要设计好  比如监控用redis  可以用缓存  因为监控  在很长一段时间 数据都不会更新 所以用key  把缓存的数据存入redis  减少数据库io  这就很合理  一种就是简单粗暴的
直接扩容  一种就是优化数据存储架构


map(lambal )
filer  都是返回迭代对象需要转换成list

还有yaml  读取f.read  然后组织成yaml的数据库结构 写入yaml  f.write  然后调用加载yamlload把 文件序列加载到内存就是和dump  load一样的原理  然后yamldump把加载到内存中的对象转成json串
写入到文件

网上一些网站 视频采集网站也是用的  定时任务  所以我们不能用监控去做 视频采集的更新  监控只能有少数任务 而不适用于大量任务  而且要并行  同时监控采集但是 这样过于占用资源太过频繁  当任务过多时
就不适用  特定任务可以 
所以我们要分析   视频网站定时更新的时间是什么时候 怎么去研究   可以写一个监控某一个特定视频更新的时间点去推算  我们定时更新的时间点  我们定时更新的时间点一定要在  视频采集更新时间点之后

